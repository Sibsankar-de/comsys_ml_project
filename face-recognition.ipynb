{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab077d5",
   "metadata": {},
   "source": [
    "## Face Recognition with Custom Dataset and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49a6c2",
   "metadata": {},
   "source": [
    "### Facerecognition Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5302d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognitionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_map = {}\n",
    "\n",
    "        # Assign one label per folder (001_frontal, 002_frontal, etc.)\n",
    "        all_folders = sorted([f for f in self.root_dir.iterdir() if f.is_dir()])\n",
    "        for label_idx, person_folder in enumerate(all_folders):\n",
    "            identity = person_folder.name\n",
    "            self.label_map[identity] = label_idx\n",
    "\n",
    "            # Get all image files in this identity folder (including distortion subfolder)\n",
    "            for image_path in person_folder.glob(\"*.jpg\"):\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(label_idx)\n",
    "\n",
    "            distortion_folder = person_folder / \"distortion\"\n",
    "            if distortion_folder.exists():\n",
    "                for distorted_image in distortion_folder.glob(\"*.jpg\"):\n",
    "                    self.image_paths.append(distorted_image)\n",
    "                    self.labels.append(label_idx)\n",
    "\n",
    "        self.classes = list(self.label_map.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a766f04",
   "metadata": {},
   "source": [
    "### Transforms and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff8926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes: 877\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = FaceRecognitionDataset(root_dir='./data-set/Task_B/train', transform=transform)\n",
    "val_dataset = FaceRecognitionDataset(root_dir='./data-set/Task_B/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.label_map)\n",
    "print(\"Total Classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c6de4",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ce7cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0217ac",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30e5229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc045c",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8013adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a908c",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7afd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device, class_names=None):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    if class_names and len(class_names) == len(set(all_labels)):\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    else:\n",
    "        print(\"⚠ Skipping target_names due to mismatch.\")\n",
    "        print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, xticklabels=False, yticklabels=False, annot=False, cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeac1d2",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Epoch [1/10] - Loss: 3.3632\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 2/10\n",
      "Epoch [2/10] - Loss: 0.9687\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 3/10\n",
      "Epoch [3/10] - Loss: 0.1539\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 4/10\n",
      "Epoch [4/10] - Loss: 0.0456\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 5/10\n",
      "Epoch [5/10] - Loss: 0.0243\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 6/10\n",
      "Epoch [6/10] - Loss: 0.0146\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 7/10\n",
      "Epoch [7/10] - Loss: 0.0096\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 8/10\n",
      "Epoch [8/10] - Loss: 0.0067\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 9/10\n",
      "Epoch [9/10] - Loss: 0.0049\n",
      "✅ Saved best model so far.\n",
      "\n",
      "Epoch 10/10\n",
      "Epoch [10/10] - Loss: 0.0036\n",
      "✅ Saved best model so far.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 408, does not match size of target_names, 877. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Final Evaluation\u001b[39;00m\n\u001b[32m     16\u001b[39m class_names = \u001b[38;5;28mlist\u001b[39m(train_dataset.label_map.keys())\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, loader, device, class_names)\u001b[39m\n\u001b[32m     10\u001b[39m         all_preds.extend(preds)\n\u001b[32m     11\u001b[39m         all_labels.extend(labels.numpy())\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     15\u001b[39m cm = confusion_matrix(all_labels, all_preds)\n\u001b[32m     16\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2945\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2939\u001b[39m         warnings.warn(\n\u001b[32m   2940\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2941\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[32m   2942\u001b[39m             )\n\u001b[32m   2943\u001b[39m         )\n\u001b[32m   2944\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2945\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2946\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2947\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m. Try specifying the labels \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2948\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[32m   2949\u001b[39m         )\n\u001b[32m   2950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2951\u001b[39m     target_names = [\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[31mValueError\u001b[39m: Number of classes, 408, does not match size of target_names, 877. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "best_loss = float('inf')  # for saving the best model only\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Loss: {loss:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), \"best_face_model.pth\")\n",
    "        print(\"✅ Saved best model so far.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efcdc8",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c630ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sibsankar De\\AppData\\Local\\Temp\\ipykernel_43228\\725786416.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_face_model.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=877, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_face_model.pth', map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b954c05",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13f5b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Skipping target_names due to mismatch.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00         8\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.00      0.00      0.00         8\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         8\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.00      0.00      0.00         8\n",
      "          23       0.00      0.00      0.00         8\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         8\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.00      0.00      0.00        32\n",
      "          29       0.00      0.00      0.00         8\n",
      "          30       0.00      0.00      0.00        16\n",
      "          31       0.00      0.00      0.00        40\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       0.00      0.00      0.00         8\n",
      "          35       0.00      0.00      0.00         8\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         8\n",
      "          39       0.00      0.00      0.00         8\n",
      "          40       0.00      0.00      0.00         8\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         8\n",
      "          43       0.00      0.00      0.00         8\n",
      "          44       0.00      0.00      0.00        16\n",
      "          45       0.00      0.00      0.00         8\n",
      "          46       0.00      0.00      0.00         8\n",
      "          47       0.00      0.00      0.00         8\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         8\n",
      "          50       0.00      0.00      0.00         8\n",
      "          51       0.00      0.00      0.00        16\n",
      "          52       0.00      0.00      0.00         8\n",
      "          53       0.00      0.00      0.00        24\n",
      "          54       0.00      0.00      0.00         8\n",
      "          55       0.00      0.00      0.00        24\n",
      "          56       0.00      0.00      0.00        24\n",
      "          57       0.00      0.00      0.00        32\n",
      "          58       0.00      0.00      0.00         8\n",
      "          59       0.00      0.00      0.00         8\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         8\n",
      "          62       0.00      0.00      0.00         8\n",
      "          63       0.00      0.00      0.00        32\n",
      "          64       0.00      0.00      0.00         8\n",
      "          65       0.00      0.00      0.00         8\n",
      "          66       0.00      0.00      0.00         8\n",
      "          67       0.00      0.00      0.00         8\n",
      "          68       0.00      0.00      0.00         8\n",
      "          69       0.00      0.00      0.00         8\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.00      0.00      0.00         8\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        16\n",
      "          74       0.00      0.00      0.00         8\n",
      "          75       0.00      0.00      0.00         8\n",
      "          76       0.00      0.00      0.00         8\n",
      "          77       0.00      0.00      0.00         8\n",
      "          78       0.00      0.00      0.00         8\n",
      "          79       0.00      0.00      0.00         8\n",
      "          80       0.00      0.00      0.00        16\n",
      "          81       0.00      0.00      0.00         8\n",
      "          82       0.00      0.00      0.00         8\n",
      "          83       0.00      0.00      0.00         8\n",
      "          84       0.00      0.00      0.00        16\n",
      "          85       0.00      0.00      0.00         8\n",
      "          86       0.00      0.00      0.00         8\n",
      "          87       0.00      0.00      0.00         8\n",
      "          88       0.00      0.00      0.00         8\n",
      "          89       0.00      0.00      0.00        16\n",
      "          90       0.00      0.00      0.00        40\n",
      "          91       0.00      0.00      0.00        40\n",
      "          92       0.00      0.00      0.00        16\n",
      "          93       0.00      0.00      0.00         8\n",
      "          94       0.00      0.00      0.00         8\n",
      "          95       0.00      0.00      0.00         8\n",
      "          96       0.00      0.00      0.00        16\n",
      "          97       0.00      0.00      0.00        32\n",
      "          98       0.00      0.00      0.00         8\n",
      "          99       0.00      0.00      0.00         8\n",
      "         100       0.00      0.00      0.00        16\n",
      "         101       0.00      0.00      0.00         8\n",
      "         102       0.00      0.00      0.00         8\n",
      "         103       0.00      0.00      0.00         8\n",
      "         104       0.00      0.00      0.00         8\n",
      "         105       0.00      0.00      0.00         8\n",
      "         106       0.00      0.00      0.00         8\n",
      "         107       0.00      0.00      0.00         8\n",
      "         108       0.00      0.00      0.00         8\n",
      "         109       0.00      0.00      0.00        24\n",
      "         110       0.00      0.00      0.00        24\n",
      "         111       0.00      0.00      0.00         8\n",
      "         112       0.00      0.00      0.00         8\n",
      "         113       0.00      0.00      0.00        24\n",
      "         114       0.00      0.00      0.00        96\n",
      "         115       0.00      0.00      0.00         8\n",
      "         116       0.00      0.00      0.00         8\n",
      "         117       0.00      0.00      0.00         8\n",
      "         118       0.00      0.00      0.00         8\n",
      "         119       0.00      0.00      0.00         8\n",
      "         120       0.00      0.00      0.00        24\n",
      "         121       0.00      0.00      0.00         8\n",
      "         122       0.00      0.00      0.00         8\n",
      "         123       0.00      0.00      0.00        40\n",
      "         124       0.00      0.00      0.00         8\n",
      "         125       0.00      0.00      0.00        16\n",
      "         126       0.00      0.00      0.00         8\n",
      "         127       0.00      0.00      0.00        32\n",
      "         128       0.00      0.00      0.00         8\n",
      "         129       0.00      0.00      0.00         8\n",
      "         130       0.00      0.00      0.00        16\n",
      "         131       0.00      0.00      0.00         8\n",
      "         132       0.00      0.00      0.00         8\n",
      "         133       0.00      0.00      0.00         8\n",
      "         134       0.00      0.00      0.00         8\n",
      "         135       0.00      0.00      0.00         8\n",
      "         136       0.00      0.00      0.00         8\n",
      "         137       0.00      0.00      0.00         8\n",
      "         138       0.00      0.00      0.00         8\n",
      "         139       0.00      0.00      0.00         8\n",
      "         140       0.00      0.00      0.00         8\n",
      "         141       0.00      0.00      0.00         8\n",
      "         142       0.00      0.00      0.00         8\n",
      "         143       0.00      0.00      0.00         8\n",
      "         144       0.00      0.00      0.00        16\n",
      "         145       0.00      0.00      0.00        40\n",
      "         146       0.00      0.00      0.00         8\n",
      "         147       0.00      0.00      0.00        16\n",
      "         148       0.00      0.00      0.00         8\n",
      "         149       0.00      0.00      0.00         8\n",
      "         150       0.00      0.00      0.00        32\n",
      "         151       0.00      0.00      0.00         8\n",
      "         152       0.00      0.00      0.00         8\n",
      "         153       0.00      0.00      0.00        16\n",
      "         154       0.00      0.00      0.00         8\n",
      "         155       0.00      0.00      0.00         8\n",
      "         156       0.00      0.00      0.00         8\n",
      "         157       0.00      0.00      0.00         8\n",
      "         158       0.00      0.00      0.00         8\n",
      "         159       0.00      0.00      0.00        16\n",
      "         160       0.00      0.00      0.00        16\n",
      "         161       0.00      0.00      0.00         8\n",
      "         162       0.00      0.00      0.00         8\n",
      "         163       0.00      0.00      0.00         8\n",
      "         164       0.00      0.00      0.00         8\n",
      "         165       0.00      0.00      0.00         8\n",
      "         166       0.00      0.00      0.00         8\n",
      "         167       0.00      0.00      0.00         8\n",
      "         168       0.00      0.00      0.00         8\n",
      "         169       0.00      0.00      0.00         8\n",
      "         170       0.00      0.00      0.00        16\n",
      "         171       0.00      0.00      0.00        16\n",
      "         172       0.00      0.00      0.00         8\n",
      "         173       0.00      0.00      0.00         8\n",
      "         174       0.00      0.00      0.00         8\n",
      "         175       0.00      0.00      0.00         8\n",
      "         176       0.00      0.00      0.00         8\n",
      "         177       0.00      0.00      0.00         8\n",
      "         178       0.00      0.00      0.00         8\n",
      "         179       0.00      0.00      0.00         8\n",
      "         180       0.00      0.00      0.00         8\n",
      "         181       0.00      0.00      0.00         8\n",
      "         182       0.00      0.00      0.00         8\n",
      "         183       0.00      0.00      0.00         8\n",
      "         184       0.00      0.00      0.00         8\n",
      "         185       0.00      0.00      0.00         8\n",
      "         186       0.00      0.00      0.00         8\n",
      "         187       0.00      0.00      0.00        16\n",
      "         188       0.00      0.00      0.00         8\n",
      "         189       0.00      0.00      0.00         8\n",
      "         190       0.00      0.00      0.00         8\n",
      "         191       0.00      0.00      0.00        24\n",
      "         192       0.00      0.00      0.00        16\n",
      "         193       0.00      0.00      0.00         8\n",
      "         194       0.00      0.00      0.00        32\n",
      "         195       0.00      0.00      0.00        32\n",
      "         196       0.00      0.00      0.00         8\n",
      "         197       0.00      0.00      0.00        16\n",
      "         198       0.00      0.00      0.00       160\n",
      "         199       0.56      0.06      0.10        88\n",
      "         200       0.00      0.00      0.00        16\n",
      "         201       0.00      0.00      0.00         8\n",
      "         202       0.00      0.00      0.00        40\n",
      "         203       0.00      0.00      0.00        32\n",
      "         204       0.00      0.00      0.00         8\n",
      "         205       0.00      0.00      0.00         8\n",
      "         206       0.00      0.00      0.00        32\n",
      "         207       0.00      0.00      0.00         8\n",
      "         208       0.00      0.00      0.00         8\n",
      "         209       0.00      0.00      0.00        16\n",
      "         210       0.00      0.00      0.00        16\n",
      "         211       0.00      0.00      0.00        24\n",
      "         212       0.00      0.00      0.00        32\n",
      "         213       0.00      0.00      0.00         8\n",
      "         214       0.00      0.00      0.00         8\n",
      "         215       0.00      0.00      0.00         8\n",
      "         216       0.00      0.00      0.00         8\n",
      "         217       0.00      0.00      0.00        64\n",
      "         218       0.00      0.00      0.00         8\n",
      "         219       0.00      0.00      0.00        24\n",
      "         220       0.00      0.00      0.00         8\n",
      "         221       0.00      0.00      0.00        16\n",
      "         222       1.00      0.06      0.12        16\n",
      "         223       0.00      0.00      0.00         8\n",
      "         224       0.00      0.00      0.00         8\n",
      "         225       0.00      0.00      0.00         8\n",
      "         226       0.00      0.00      0.00         8\n",
      "         227       0.00      0.00      0.00        16\n",
      "         228       0.00      0.00      0.00         8\n",
      "         229       0.00      0.00      0.00         8\n",
      "         230       0.00      0.00      0.00        48\n",
      "         231       0.00      0.00      0.00         8\n",
      "         232       1.00      0.25      0.40         8\n",
      "         233       0.00      0.00      0.00        16\n",
      "         234       0.00      0.00      0.00         8\n",
      "         235       0.00      0.00      0.00         8\n",
      "         236       0.00      0.00      0.00        16\n",
      "         237       0.00      0.00      0.00         8\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         8\n",
      "         240       0.00      0.00      0.00         8\n",
      "         241       0.00      0.00      0.00        16\n",
      "         242       0.00      0.00      0.00       104\n",
      "         243       0.00      0.00      0.00         8\n",
      "         244       0.00      0.00      0.00         8\n",
      "         245       0.00      0.00      0.00         8\n",
      "         246       0.02      0.88      0.03         8\n",
      "         247       0.00      0.00      0.00         8\n",
      "         248       0.00      0.00      0.00         8\n",
      "         249       0.00      0.00      0.00         8\n",
      "         250       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         0\n",
      "         269       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         283       0.00      0.00      0.00         0\n",
      "         284       0.00      0.00      0.00         0\n",
      "         285       0.00      0.00      0.00         0\n",
      "         287       0.00      0.00      0.00         0\n",
      "         297       0.00      0.00      0.00         0\n",
      "         302       0.00      0.00      0.00         0\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         0\n",
      "         321       0.00      0.00      0.00         0\n",
      "         342       0.00      0.00      0.00         0\n",
      "         345       0.00      0.00      0.00         0\n",
      "         346       0.00      0.00      0.00         0\n",
      "         348       0.00      0.00      0.00         0\n",
      "         349       0.00      0.00      0.00         0\n",
      "         363       0.00      0.00      0.00         0\n",
      "         365       0.00      0.00      0.00         0\n",
      "         374       0.00      0.00      0.00         0\n",
      "         375       0.00      0.00      0.00         0\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.00      0.00      0.00         0\n",
      "         382       0.00      0.00      0.00         0\n",
      "         383       0.00      0.00      0.00         0\n",
      "         389       0.00      0.00      0.00         0\n",
      "         390       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         0\n",
      "         399       0.00      0.00      0.00         0\n",
      "         402       0.00      0.00      0.00         0\n",
      "         406       0.00      0.00      0.00         0\n",
      "         417       0.00      0.00      0.00         0\n",
      "         419       0.00      0.00      0.00         0\n",
      "         429       0.00      0.00      0.00         0\n",
      "         437       0.00      0.00      0.00         0\n",
      "         440       0.00      0.00      0.00         0\n",
      "         443       0.00      0.00      0.00         0\n",
      "         446       0.00      0.00      0.00         0\n",
      "         449       0.00      0.00      0.00         0\n",
      "         451       0.00      0.00      0.00         0\n",
      "         453       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.00      0.00      0.00         0\n",
      "         475       0.00      0.00      0.00         0\n",
      "         479       0.00      0.00      0.00         0\n",
      "         483       0.00      0.00      0.00         0\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       0.00      0.00      0.00         0\n",
      "         489       0.00      0.00      0.00         0\n",
      "         491       0.00      0.00      0.00         0\n",
      "         495       0.00      0.00      0.00         0\n",
      "         496       0.00      0.00      0.00         0\n",
      "         506       0.00      0.00      0.00         0\n",
      "         507       0.00      0.00      0.00         0\n",
      "         512       0.00      0.00      0.00         0\n",
      "         515       0.00      0.00      0.00         0\n",
      "         520       0.00      0.00      0.00         0\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       0.00      0.00      0.00         0\n",
      "         533       0.00      0.00      0.00         0\n",
      "         534       0.00      0.00      0.00         0\n",
      "         535       0.00      0.00      0.00         0\n",
      "         538       0.00      0.00      0.00         0\n",
      "         541       0.00      0.00      0.00         0\n",
      "         542       0.00      0.00      0.00         0\n",
      "         556       0.00      0.00      0.00         0\n",
      "         557       0.00      0.00      0.00         0\n",
      "         562       0.00      0.00      0.00         0\n",
      "         568       0.00      0.00      0.00         0\n",
      "         569       0.00      0.00      0.00         0\n",
      "         576       0.00      0.00      0.00         0\n",
      "         577       0.00      0.00      0.00         0\n",
      "         584       0.00      0.00      0.00         0\n",
      "         585       0.00      0.00      0.00         0\n",
      "         587       0.00      0.00      0.00         0\n",
      "         588       0.00      0.00      0.00         0\n",
      "         598       0.00      0.00      0.00         0\n",
      "         599       0.00      0.00      0.00         0\n",
      "         603       0.00      0.00      0.00         0\n",
      "         604       0.00      0.00      0.00         0\n",
      "         609       0.00      0.00      0.00         0\n",
      "         612       0.00      0.00      0.00         0\n",
      "         613       0.00      0.00      0.00         0\n",
      "         616       0.00      0.00      0.00         0\n",
      "         618       0.00      0.00      0.00         0\n",
      "         624       0.00      0.00      0.00         0\n",
      "         630       0.00      0.00      0.00         0\n",
      "         631       0.00      0.00      0.00         0\n",
      "         640       0.00      0.00      0.00         0\n",
      "         642       0.00      0.00      0.00         0\n",
      "         653       0.00      0.00      0.00         0\n",
      "         655       0.00      0.00      0.00         0\n",
      "         656       0.00      0.00      0.00         0\n",
      "         662       0.00      0.00      0.00         0\n",
      "         663       0.00      0.00      0.00         0\n",
      "         669       0.00      0.00      0.00         0\n",
      "         670       0.00      0.00      0.00         0\n",
      "         673       0.00      0.00      0.00         0\n",
      "         678       0.00      0.00      0.00         0\n",
      "         679       0.00      0.00      0.00         0\n",
      "         680       0.00      0.00      0.00         0\n",
      "         681       0.00      0.00      0.00         0\n",
      "         683       0.00      0.00      0.00         0\n",
      "         684       0.00      0.00      0.00         0\n",
      "         686       0.00      0.00      0.00         0\n",
      "         687       0.00      0.00      0.00         0\n",
      "         696       0.00      0.00      0.00         0\n",
      "         699       0.00      0.00      0.00         0\n",
      "         701       0.00      0.00      0.00         0\n",
      "         704       0.00      0.00      0.00         0\n",
      "         710       0.00      0.00      0.00         0\n",
      "         714       0.00      0.00      0.00         0\n",
      "         715       0.00      0.00      0.00         0\n",
      "         717       0.00      0.00      0.00         0\n",
      "         724       0.00      0.00      0.00         0\n",
      "         727       0.00      0.00      0.00         0\n",
      "         729       0.00      0.00      0.00         0\n",
      "         731       0.00      0.00      0.00         0\n",
      "         737       0.00      0.00      0.00         0\n",
      "         738       0.00      0.00      0.00         0\n",
      "         739       0.00      0.00      0.00         0\n",
      "         740       0.00      0.00      0.00         0\n",
      "         742       0.00      0.00      0.00         0\n",
      "         747       0.00      0.00      0.00         0\n",
      "         752       0.00      0.00      0.00         0\n",
      "         763       0.00      0.00      0.00         0\n",
      "         765       0.00      0.00      0.00         0\n",
      "         771       0.00      0.00      0.00         0\n",
      "         772       0.00      0.00      0.00         0\n",
      "         775       0.00      0.00      0.00         0\n",
      "         776       0.00      0.00      0.00         0\n",
      "         781       0.00      0.00      0.00         0\n",
      "         792       0.00      0.00      0.00         0\n",
      "         793       0.00      0.00      0.00         0\n",
      "         806       0.00      0.00      0.00         0\n",
      "         809       0.00      0.00      0.00         0\n",
      "         821       0.00      0.00      0.00         0\n",
      "         822       0.00      0.00      0.00         0\n",
      "         823       0.00      0.00      0.00         0\n",
      "         825       0.00      0.00      0.00         0\n",
      "         831       0.00      0.00      0.00         0\n",
      "         833       0.00      0.00      0.00         0\n",
      "         834       0.00      0.00      0.00         0\n",
      "         835       0.00      0.00      0.00         0\n",
      "         838       0.00      0.00      0.00         0\n",
      "         845       0.00      0.00      0.00         0\n",
      "         854       0.00      0.00      0.00         0\n",
      "         855       0.00      0.00      0.00         0\n",
      "         856       0.00      0.00      0.00         0\n",
      "         857       0.00      0.00      0.00         0\n",
      "         865       0.00      0.00      0.00         0\n",
      "         866       0.00      0.00      0.00         0\n",
      "         869       0.00      0.00      0.00         0\n",
      "         871       0.00      0.00      0.00         0\n",
      "         876       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00      3376\n",
      "   macro avg       0.01      0.00      0.00      3376\n",
      "weighted avg       0.02      0.00      0.00      3376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sibsankar De\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final Evaluation\n",
    "class_names = list(train_dataset.label_map.keys())\n",
    "evaluate_model(model, val_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9d6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, transform, label_map):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        pred = torch.argmax(output, dim=1).item()\n",
    "    return list(label_map.keys())[list(label_map.values()).index(pred)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
